# s 
45
## url
https://towardsdatascience.com/the-anatomy-of-a-data-product-d3140f068311
## tiny url
https://tinyurl.com/data-as-a-product-s45
## archive url
https://bit.ly/data-as-a-product-s45
## title
The Anatomy of a Data Product
## source code

## example

## source type 
Practitioner Audience Article
## author type
Practitioner
## references

**AXIAL CODING TRACE**: source and references
``` python
s45 = CClass(source, "s45", values={
    "title": "The Anatomy of a Data Product",
    "url": "https://towardsdatascience.com/the-anatomy-of-a-data-product-d3140f068311",
    "archive url": "https://bit.ly/data-as-a-product-s45",
    "author type": "Practitioner Audience Article",
    "type": "Practitioner",
    "example": True,
    "source code": False})
``` 

# coding

> The Anatomy of a Data Product

> Data Products are the foundational building block of an enterprise Data Mesh. But what exactly is a Data Product, how do they work, how can they be identified, and how can they be built quickly?

![Anatomy](https://miro.medium.com/max/720/1*9_RqbXoji0JYQqScPq8AmQ.webp)

> Making Data Easy to Find, Share, Consume, and Govern
I think of Data Products by the value they provide to an organization: Data Products (and the Data Mesh within which they operate) make data easy to find, consume, share, and govern. And to deliver this value, our job as a practitioner is to make Data Products easy to build, deploy, secure, and manage.
In this article I will answer two key questions:
How are data products designed, and how to they work such that they make data easy to find, consume, share, and govern?
What capabilities, APIs, and lifecycle needs to be established to make Data Products easy to build, deploy, secure, and manage?
Simply put, if you can answer these questions, then, first, you will be able to explain why Data Products are foundational to your Data Mesh journey, and second, you will understand the capabilities necessary to accelerate the adoption and buildout of Data Products in your enterprise Data Mesh.
Before you start, this article assumes that you have a high-level understanding of Data Mesh. If you need some background information on Data Mesh, there are a number of great articles are available here (patterns), here (architecture), here (principles) and here (lessons learned). For interested readers, a full set of Data Mesh patterns are available here and here.

> Data Product = Data Domains + Product Thinking
In her fantastic book, Data Mesh, Delivering Data-Driven Value at Scale, Zhamak Dehghani says that Data Products are the “architecture quantum” in a Data Mesh. They are “the smallest unit of architect that can be independently deployed and managed.” She goes on to say that Data Products are “discoverable, understandable, trustworthy, addressable, interoperable, and composable, secure, natively accessible, and valuable on its own”.
I would offer a complementary definition: A data product is the combination of a “data domain” and “product thinking”.

![ProductThinking](https://miro.medium.com/max/720/1*CX2EuXKxsqUnOEGh3WMugw.webp)

> Let’s unpack this a bit starting with “product thinking”. I like some insights found in a recent article in Harvard Business Review: First, a product marshals an organization’s production capabilities to “deliver and capture value”. Second, there is an “end customer who purchases and uses that product”. Lastly, a Product has an owner and team that creates a long-term plan to ensure that “products can be continuously improved to make them more successful” delivered by a group that focusses on “outcomes instead of outputs”.
To paraphrase, product thinking means that ensuring your product meets a specific business need and delivers some tangible value, has a long-term time horizon, and has a clear and empowered owner that acts in not only the enterprise’s but also the customer’s interest.
Unfortunately, defining “data domain” is not as simple since this term tends to be quite ambiguous in large enterprises. For the Chief Data Officer, governance, regulation, and privacy are a central concern leading to coarsely grained domains: All customers instead of current customers, or Canadian customers, for example.
Similarly, the data architect may consider customers to be a subset of the “party” domain which includes, current clients as well prospects. And the application developer may view customers as unique identifier linking a customer’s accounts and transactions.
For the purposes of this article, I define a data domain as a set of identifiable, real, related data that is managed consistently, and which has some measure of quality and accuracy.
So, now let’s combine these ideas and create a practical definition of a Data Products. A Data Product has/is:
Clear boundaries, to establish an identifiable set of related data
An empowered owner, to provide the organizational resources and decision making needed to make data valuable and trustworthy, and provide a long-term view of the product’s evolution
Part of an ecosystem of consumers and producers, that demands data interoperability, consistency, and quality to deliver value to the enterprise
Enabled by a platform, that makes data discoverable, addressable, accessible, and interoperable
Published metadata, that enables discovery and self-serve while making data understandable
Federated governance, recognizes the power of local autonomy to implement enterprise policies and make data secure

>  Architecture of a Data Product
With this definition in hand, let’s explore the architecture of a data product.

![Architecture](https://miro.medium.com/max/720/1*e_kC0LEOIClJlxxJRIR_kg.webp)

> A Data Product architect has components that make it:
Interoperable: Interoperable interfaces — queries as well as APIs, pipelines, files, and events — are available to address consumption and ingestion needs. Additional interfaces, typically implemented as APIs, are also available to observe, operate, secure, and manage the data product. Each interface has a contract (for example, APIs use OpenAPI specifications) that formalize interactions.
Bounded: Data products store any type of data that has a clearly defined boundary and owner; While analytic data is a primary use case, both operational and engagement data can also be managed with in a data product.
Self-Aware: Automatically capturing changes and information about itself; All data product changes can be captured and distributed as “events” within the data product, to other data products, or to interested parties across the enterprise.
Discoverable: Each data product contains its own “Registry” that publishes its data product metadata, ownership information, policies, and any additional enabling behaviours; The data product registry is the “one-stop-shop” for developers, data scientists, and data analysts to find, consume, share, and govern data managed by a specific data product. It also is the entry point to behaviours specific to that data product enabling sophisticated interactions allowing users to request access to data, or “owners” to create new data products.
Secure: Data products ensure that all data is secure both at-rest and in-motion; Our objective is to ensure that all data products operate in a “Zero-Trust” container/environment.
Historical and Temporal: Changes to data state or exceptions using the data product are captured and managed in an immutable log to support a federated governance, diagnosis of security issues, and (when data state changes are aggregated) provide data lineage.
Shareable: A Data product has “ports” that allow data managed by the data product to be ingested or consumed. Information and events (for example, a data change or an API call) can be communicated using bulk pipelines or in near real-time inside the data product domain, between data products, as well as across the organization using a robust, reliable, and resilient backbone.

**OPEN CODING TRACE:**

Familiar options: rest_apis, central_data_product_catalogue, change_data_capture, core_datasets, domain_datasets, event_streaming, immutable_change_audit_log, register_datasets, containerisation, data_marketplace
New option: zero_trust_architecture

**AXIAL CODING TRACE:**
added:
``` python
    zero_trust_architecture = CClass(practice, "Zero Trust Architecture")
    
    add_decision_option_link(security, zero_trust_architecture,
                             "Apply a zero trust between the data products")
``` 
add codes to s45: 
``` python 
    '''
        rest_apis, 
        central_data_product_catalogue, 
        change_data_capture, 
        core_datasets, 
        domain_datasets, 
        event_streaming, 
        immutable_change_audit_log, 
        register_datasets, 
        containerisation, 
        data_marketplace
    '''
```

> Data Product Interoperable Interfaces: The Core Data Product Enabler
When we think of interoperable interfaces, there are two that are top-of-mind: the interfaces (pipelines, APIs etc) that ingest data into a data product, and the queries used to consume data in a data product.
However, in large enterprises interoperable interfaces have several expectations (in some cases mandatory requirements):
Formal Contracts: Each ingestion or consumption path — either pipelines, queries, or APIs, or events — should be defined by a formal and published contract. In some cases, the contracts will be specific to the tool used (DBT, etc) but in other cases — APIs or events — formal specifications such as OpenAPI and JSON Schemas, respectively, are common.
Formal Versioning: Contracts should be versioned thereby allowing backward compatibility. Now, in fairness, smaller environments where data is shared with few participants this may not be important. However, in larger enterprises where data is shared widely it is crucial to ensure that downstream systems do not choke when upstream systems change data formats.
Formal Security: This is tricky — each tool may offer a different security approach, and worse, some may not have a robust nor complete security model. Still, this does not negate the need for securing your producer and consumer interfaces — rather, it just makes it harder to do.

![DataProductInterfaces](https://miro.medium.com/max/720/1*H8041Vq7P7P4K3AP6EIYgA.webp)

> While the producer and consumer interfaces are important, we should not overlook the crucial nature of interfaces that enable discovery, observability, and manageability. In fact, most of these interfaces are implemented as APIs which means that you can take advantage of the capabilities offered by OpenAPI specifications:
Formal Contracts: OpenAPI and AsyncAPI specifications offer well documented, battle-tested specification that acts as a formal synch / asynch contracts for use within enterprises.
Formal Versioning: OpenAPI specifications permit a flexible method of versioning APIs to gracefully manage contract changes over time.
Formal Security: OpenAPI specifications provide a robust, well understood, and well documented approach to defining security schemas that define to “scopes” which map directly to roles; with a little bit of due diligence, these scopes can be implemented using OAUTH2 (a common security approach) and connected to an enterprise’s identity book of record.

**OPEN CODING TRACE:**

Familiar options: k8s, time_bounded_backwards_compatibility, versioning

**AXIAL CODING TRACE:**

add codes to s45: 
``` python 
    '''
        k8s
        time_bounded_backwards_compatibility,
        versioning
    '''
```

> Data Product Value Chain
A Data Product’s value increases proportionately to its use in the enterprise. At its earliest stage, a Data Product (in a Data Mesh) is discoverable, addressable, interoperable, self-describing, trustworthy, and secure. According to the originator of Data Mesh, Zhamak Dehghani, these are the basic characteristics of a data product and constitute the building blocks of all further successive value offered by the data product.
With these basic attributes in place, a data product can begin to be used in the enterprise. And if designed well, then the data product can now make data easy to find, consume, share, and govern. And as data is more easily and frequently consumed and shared, newfound agility and speed result. And with this agility and speed come true business value:
Faster and better insights, that are key to creating an outstanding customers experience or quickly addressing changing market needs.
Improved time-to-market, especially for end consumer products heavily reliant upon data.
Lower Delivery Costs, as speed and agility shorten delivery durations.

![DataProductValueChain](https://miro.medium.com/max/720/1*nhnKzQ8GID-sfkoFRzz7hA.webp)

**OPEN CODING TRACE:**

Familiar options: time_bounded_backwards_compatibility, versioning
New option: oauth2

**AXIAL CODING TRACE:**
added:
``` python
    oauth2 = CClass(practice, "OAUTH2")
    
    add_decision_option_link(security, oauth2,
                             "Apply the OAUTH2 security approach")
``` 
add codes to s45: 
``` python 
    '''
        cloud_infrastructure_layer,
        triggering
    '''
```

> But how can data products be delivered quickly, consistently, and securely? That is where the “Data Product Factory” comes in.
A Data Product Factory establishes repeatable steps to make data products:
Easy to build, by providing templates that simplify the building of a Data Product; these templates generate microservices/APIs with built-in discoverability (the “/discover” endpoint) and observability (“/observe”, “/usage”, “/logs”, and “/alerts” endpoints.
Easy to secure, by providing extensions to the aforementioned templates to enable OAUTH2 based security for each of API/microservice; and with a bit more due diligence, these templates can also target the generation a “zero-trust” run-time environment for our data product APIs/microservices and its data.
Easy to deploy, by providing extensions to the aforementioned templates to generate the APIs/microservices (and if needed, data) into a “container” (for example, Docker) or a Kubernetes Pod making it easy to deploy Data Products either to on-premises or cloud environments and relatively easily included in a DevSecOps pipeline.
Easy to manage, by hooking the generated APIs/microservices (“/logs” and “/alerts” endpoints, for example) into enterprise management and monitoring tools.

> Data Product Identification
Now we can see why Data Products are so important in our Data Mesh journey. And we have also seen how we can accelerate the delivery of Data Products using our Factory.

![DataProductIdentification](https://miro.medium.com/max/720/1*eKBARVFzzhjTetGhSkQUYQ.webp)

> So, clearly Data Products make a lot of sense! But how do we identify them? Fortunately, there are a lot of hints that help us find Data Products in an enterprise:
Conway’s Law: Applying Conway’s Law (to paraphrase, your systems and data will follow your organization structure) to Data Product means that ownership migrates to groups aligned closely to organizational units (lines of business, etc), that have deep knowledge of the data as well as direct accountability for delivering results with, and hence decision and funding rights, for the data.
CDO Data Domains: A data domain map (enterprise or group) identifies business entities that are of significant value to the enterprise. These entities provide “hints” that may identify data product candidates. However, note that in may cases enterprise domains may need to be sub-divided into finer grained domains to map to Data Products.
Business Architecture: A business architecture (enterprise or group) identifies important business capabilities. These capabilities usually translate quite easily to data domains which, like CDO domains, provide “hints” that may identify data product candidates. Once again, enterprise domains may need to be sub-divided into finer grained domains to map to Data Products.
Industry / Commercial Models: Commercial models, constructed based upon many decades of experience, identify core entities in particular industries. In Financial Services, there are several established commercial models including those from BIAN and Teradata (FSLDM, Financial Services Logical Data Model).
But there is one lessons learned that I would be remiss not to share: Granularity matters! So-called enterprise data domains — for example: “enterprise client” — are too coarsely grained to suit a data product making it quite difficult to define data boundaries and owners. Rather finer granularity data boundaries map much better to “owners” and hence, to data products (“commercial lending clients in UK”).

> Data Mesh: An Ecosystem of Data Products
No data product stands alone. Rather all data products are part of, and operate in, an ecosystem. We call this ecosystem a “Data Mesh”.

![DataMeshEcosystem](https://miro.medium.com/max/720/1*zAWNlPSWC5J7QW_NQDOo2Q.webp)

> With this simple observation, we can now delegate several simple yet specific responsibilities to the Enterprise Data Mesh.
Chief Prognosticator of Data Mesh concept: The Data Mesh first and foremost a concept — a marketing message, an executive imperative, a demarcation for an enterprise data journey — whose primary purpose is to describe and communicate the organizational construct and logical architecture abstraction that that binds data products into an ecosystem.
The Agent of Data Product Discoverability: Data Mesh is the owner of the “Enterprise Data Product Registry”, that makes Data Products easy to find, consume, share, and govern.
Keeper of Data Product Protocols: Data Mesh establishes the protocols by which data can be shared both inside a data product, between data products, and with the broader organization. As a result, becomes a key consumer and/or stakeholder in an enterprise’s common communications, pipeline, and/or event streaming backbone.

**OPEN CODING TRACE:**

Familiar option: central_data_product_catalogue

**AXIAL CODING TRACE:**

add codes to s45: 
``` python 
    '''
        central_data_product_catalogue
    '''
```

> Concluding Thoughts
In this article I discussed how data products work such that they make data easy to find, consume, share, and govern. And I also introduced the “Data Product Factory” that makes Data Products easy to build, deploy, secure, and manage.
I am hopeful that with these insights from this article that, first, you will be able to explain why Data Products are foundational to your Data Mesh journey; And second, you will understand the capabilities necessary to accelerate the adoption and buildout of Data Products in your enterprise Data Mesh.









































**OPEN CODING TRACE:**
- <ins>Option: </ins>
- <ins>Decision: </ins>
- <ins>Context: </ins>
- <ins>Comments: </ins>

**AXIAL CODING TRACE:**
added:
``` python
#added classes: 
#added relations: 
#added links: 
``` 
add codes to s: 
``` python 
    '''
    '''
# already added: 
```
```python
add_links({s30: [api_as_contract_decision, api_contract_specified, api_contract_specified_first,
                 api_code_first, api_stability, api_modifiability,
                 separation_of_api_contract_and_domain_concerns, initial_effort_required,
                 design_and_implementation_effort, maintainability_of_api_and_consumers, api_understandability
                 ]}, role_name="contained_code")
```